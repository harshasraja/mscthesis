%à¤¬
\chapter{Results and Discussions}
\section{Introduction}
Performance of database systems is commonly measured in terms of the
\textit{Response time} and \textit{Throughput}(\todo{cite Demurjian, Berkely}).
Response time refers to the time  a database system takes to process an
operation and produce results to the end user . Measuring response time for a
database operation is similar to a black-box evaluation because it is measured
without considering the internal functioning  of the database system. According
to (\todo{cite Demurjian}) such an evaluation is ideal for a complete database
system to measure its performance and to give the users details about its
efficiency and speed in performing operations. In this thesis, response time and
throughput are the measures used to gauge the performance of Cassandra while
referential integrity validation is implemented using the \ac{API}.

Response time for each  operation that triggers  a referential integrity
validation from all the solutions are measured during the experiments.
% This included the time involved to access and retrieve metadata for the entities
% and also the time for validating referential integrity by the
% \texttt{ValidationHandler}. 
The response time of Cassandra when such validations
are not in place is also measured and considered as a baseline with which to
analyse the solutions. Such a comparison determines the degree of change in
speed of Cassandra when such overheads are introduced and gives users useful
information about how each solution affects the performance of the database
system.

The second performance measure used is \textit{Throughput} and in the
experiments, it is measured as operations per second for all the operations
triggering referential integrity validation namely, \texttt{Create},
\texttt{Update} and \texttt{Delete}.
% A single operation
% stands for each time an entity is inserted, updated or deleted. Note that only
% the operations that introduce the referential integrity validation in Cassandra
% is measured and thus \texttt{read} operations are not measured in terms of
% response time or throughput.

% It has to be noted that the operations are prone to  external factors like
% network latency, bandwidth, network routing, network workload among others which
% typically affect a network consisting of several machines and users. This is
% because the Cassandra cluster used in the experiments is deployed over a
% network that is used by many users concurrently thus exposing the operations to
% such factors. Identifying such factors and analysing them is beyond the scope of
% this thesis and the analysis is strictly in terms of how the metadata storage
% and referential integrity validation affects Cassandra's performance.

 The results from the experiments were used to
analyse the performance of the four solutions  and this is discussed in the
following sections. 
Section~\ref{sr:baseline} presents the results for the
baseline experiment where the operations performed on the entities are just as
it would be performed in Cassandra without any referential integrity validations
or constraint metadata.
Section~\ref{sr:insert} analyses the results of all the solutions for the
\texttt{insert} operation.
Section~\ref{sr:update} presents the analysis for the \texttt{update} operation
for all the solutions.
Section~\ref{sr:delete} discusses the results of the solutions for the
\texttt{delete} operation.

\newcommand{\Width}{0.5\textwidth}
\newcommand{\TB}[1]{\textbf{#1}}

\section{Overview}

  Solutions~1, 2  and 4 have approximately similar response times since the metadata 
  access for these solutions are easier as metadata is a part of the entity and 
  no additional connection to a metadata column family is required. Solution~3
  takes slightly longer than the rest of the solutions and this is because of the way
  the metadata is accessed for the entities in this solution. 
% irrespective of whether an entity is a parent or child the
% \texttt{ValidationHandler} performs the same check the metedata of the entity
% for all the solutions. It is when this check is made it is clear if the entity
% is a parent or child. 
  In this solution accessing the metadata for every 
  \texttt{Student} and \texttt{Course} entity causes the slower
  response time since a different \texttt{Metadata} column family has to be
  accessed using the connection object. This is because metadata is not cached
  for re-use in this solution. Unlike this, Solution~4 caches  metadata for
  entities and re-uses it thus saving time by not having to access a separate
  column family for each entity insertion.
% \include{chapter/results-tables}

\todo{add to tables the unit (seconds, entities per second)}

\todo{Present tables and what they mean}

\todo{Explain why solution 4 is generally better}








 
\clearpage





\newpage
\section{Insert}

	\subsection{Student}
		\begin{figure}[H]
			\subfigure[Response time]
			{\includegraphics[width=\Width]{figure/result/barplot-insert_student-rt.pdf}}
			\subfigure[Throughput]
			{\includegraphics[width=\Width]{figure/result/barplot-insert_student-tp.pdf}}
			\caption{Performance inserting students}\label{f:rd:insert-user}
		\end{figure}
\newpage
	\subsection{Course}
		\begin{figure}[H]
			\subfigure[Response time]
			{\includegraphics[width=\Width]{figure/result/barplot-insert_course-rt.pdf}}
			\subfigure[Throughput]
			{\includegraphics[width=\Width]{figure/result/barplot-insert_course-tp.pdf}}
			\caption{Performance inserting courses}\label{f:rd:insert-course}
		\end{figure}	
\newpage	
	\subsection{Enrolment}
		\begin{figure}[H]
			\subfigure[Response time]
			{\includegraphics[width=\Width]{figure/result/barplot-insert_enrolment-rt.pdf}}
			\subfigure[Throughput]
			{\includegraphics[width=\Width]{figure/result/barplot-insert_enrolment-tp.pdf}}
			\caption{Performance inserting enrolments}\label{f:rd:insert-enrolment}
		\end{figure}
		
\clearpage
\newpage
\section{Update}

	\subsection{Student}
		\begin{figure}[H]
			\subfigure[Response time]
			{\includegraphics[width=\Width]{figure/result/barplot-update_student-rt.pdf}}
			\subfigure[Throughput]
			{\includegraphics[width=\Width]{figure/result/barplot-update_student-tp.pdf}}
			\caption{Performance updating students}\label{f:rd:update-user}
		\end{figure}
\newpage	
	\subsection{Course} 
		\begin{figure}[H]
			\subfigure[Response time]
			{\includegraphics[width=\Width]{figure/result/barplot-update_course-rt.pdf}}
			\subfigure[Throughput]
			{\includegraphics[width=\Width]{figure/result/barplot-update_course-tp.pdf}}
			\caption{Performance updating courses}\label{f:rd:update-course}
		\end{figure}	
\newpage	
	\subsection{Enrolment}
		\begin{figure}[H]
			\subfigure[Response time]
			{\includegraphics[width=\Width]{figure/result/barplot-update_enrolment-rt.pdf}}
			\subfigure[Throughput]
			{\includegraphics[width=\Width]{figure/result/barplot-update_enrolment-tp.pdf}}
			\caption{Performance updating enrolments}\label{f:rd:update-enrolment}
		\end{figure}
\clearpage
\newpage
\section{Delete} 

	\subsection{Student}
		\begin{figure}[H]
			\subfigure[Response time]
			{\includegraphics[width=\Width]{figure/result/barplot-delete_student-rt.pdf}}
			\subfigure[Throughput]
			{\includegraphics[width=\Width]{figure/result/barplot-delete_student-tp.pdf}}
			\caption{Performance deleting students}\label{f:rd:delete-user}
		\end{figure} 
\newpage	  
	\subsection{Course}
		\begin{figure}[H]
			\subfigure[Response time]
			{\includegraphics[width=\Width]{figure/result/barplot-delete_course-rt.pdf}}
			\subfigure[Throughput]
			{\includegraphics[width=\Width]{figure/result/barplot-delete_course-tp.pdf}}
			\caption{Performance deleting courses}\label{f:rd:delete-course}
		\end{figure}	
\newpage	 
	\subsection{Enrolment}
		\begin{figure}[H]
			\subfigure[Response time]
			{\includegraphics[width=\Width]{figure/result/barplot-delete_enrolment-rt.pdf}}
			\subfigure[Throughput]
			{\includegraphics[width=\Width]{figure/result/barplot-delete_enrolment-tp.pdf}}
			\caption{Performance deleting enrolments}\label{f:rd:delete-enrolment}
		\end{figure}
		


	